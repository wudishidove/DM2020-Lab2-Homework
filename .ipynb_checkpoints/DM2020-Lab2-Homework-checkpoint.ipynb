{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name:劉宇凌\n",
    "\n",
    "Student ID: 109136505\n",
    "\n",
    "GitHub ID: wudishidove\n",
    "\n",
    "Kaggle name: 水鬼不要QQ\n",
    "\n",
    "Kaggle private scoreboard snapshot: https://imgur.com/a/bPRBHrw\n",
    "<img src=\" https://imgur.com/iFkFbqE.png\" />\n",
    "\n",
    "\"[Snapshot](img/pic0.png)\"\n",
    "<img src=\"img/pic0.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM2020-Lab2-Master Repo](https://github.com/fhcalderon87/DM2020-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/c/dm2020-hw2-nthu/) regarding Emotion Recognition on Twitter. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the score (ie. 20% of 30% )\n",
    "\n",
    "    - **Top 41% - 100%**: Get (101-x)% of the score, where x is your ranking in the leaderboard (ie. (101-x)% of 30% )   \n",
    "    Submit your last submission __BEFORE the deadline (Dec. 5th 11:59 pm, Saturday)__. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "You can submit your homework following these guidelines: [Git Intro & How to hand your homework](https://github.com/fhcalderon87/DM2020-Lab1-Master/blob/master/Git%20Intro%20%26%20How%20to%20hand%20your%20homework.ipynb), but make sure to fork the [DM2020-Lab2-Homework](https://github.com/fhcalderon87/DM2020-Lab2-Homework) repository this time! Also please __DON´T UPLOAD HUGE DOCUMENTS__, please use Git ignore for that.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Dec. 8th 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report of kaggle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "#read data\n",
    "df = pd.read_csv('data_identification.csv')\n",
    "em = pd.read_csv('emotion.csv')\n",
    "sample=pd.read_csv('sampleSubmission.csv')\n",
    "usr= pd.read_json('tweets_DM.json',lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check data long and divide into train data & test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "train_x=df.loc[lambda a: a.identification=='train']\n",
    "test_x=df.loc[lambda a: a.identification=='test']\n",
    "usr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將pd.read_json沒展開完全的資料展開"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#展開json中間的 tweet.hashtag text.......\n",
    "test=pd.io.json.json_normalize(usr['_source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get what data I want in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joint two json dataframe\n",
    "usr2=pd.concat([test[test.columns[1]],usr[usr.columns[0]]], axis=1)\n",
    "\n",
    "usr2=pd.concat([usr2, test[test.columns[0]]], axis=1)\n",
    "\n",
    "usr2=pd.concat([usr2, test[test.columns[2]]], axis=1)\n",
    "usr2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rename index and joint the Data by user ID,\n",
    "## then add emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the index\n",
    "usr2=usr2.rename(columns={'tweet.tweet_id':'tweet_id'})\n",
    "usr2.head()\n",
    "#merge with train_user by ID \n",
    "final=pd.merge(train_x,usr2)\n",
    "#check\n",
    "final.head(20)\n",
    "final.shape\n",
    "# add motion\n",
    "final2=pd.merge(final,em)\n",
    "#check\n",
    "final2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as test data\n",
    "testData=pd.merge(test_x,usr2)\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transform the text into feature by TFIDF\n",
    "transform feature by word based and character based\n",
    "then stack two transform features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn import preprocessing, model_selection, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score, make_scorer, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word based\n",
    "tfv_word = TfidfVectorizer(min_df=150,  max_features= 100000,strip_accents='unicode',analyzer='word',token_pattern=r'\\w{1,}',ngram_range=(1,5),stop_words = 'english')\n",
    "tfv_word.fit(final2['tweet.text'])\n",
    "train_tfv_word =  tfv_word.transform(final2['tweet.text'])\n",
    "test_tfv_word = tfv_word.transform(testData['tweet.text'])\n",
    "# character based\n",
    "tfv_char = TfidfVectorizer(sublinear_tf=True,strip_accents='unicode',analyzer='char',stop_words='english',ngram_range=(2, 6),max_features=100000)\n",
    "tfv_char.fit(final2['tweet.text'])\n",
    "train_tfv_char = tfv_char.transform(final2['tweet.text'])\n",
    "test_tfv_char = tfv_char.transform(testData['tweet.text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 疊起來\n",
    "train_tfidf = hstack([train_tfv_word, train_tfv_char])\n",
    "test_tfidf = hstack([test_tfv_word, test_tfv_char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic Regression\n",
    "y = final2['emotion']\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_tfidf, y)\n",
    "tf_predict = lr.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change datatype from array to pd\n",
    "tf_predict2=pd.DataFrame(tf_predict)\n",
    "tf_predict2.head()\n",
    "temp=tf_predict2\n",
    "#temp.head()\n",
    "#add id into output\n",
    "output=pd.concat([testData['tweet_id'], temp], axis=1)\n",
    "#output.head()\n",
    "\n",
    "#rename\n",
    "output=output.rename(columns={'tweet_id':'id'})\n",
    "#output[lambda a: a.'0'=='emotion']\n",
    "output=output.rename(columns={0:'emotion'})\n",
    "output.head()\n",
    "\n",
    "#saveFile\n",
    "output.to_csv('preditOutput6.csv', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what i found and what else i try \n",
    "### i found text transform feature increase can improve the accuracy\n",
    "### below cell is what i try in tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_features= 10000\n",
    "#max_features= 25000\n",
    "#max_features= 40000\n",
    "#max_features= 50000\n",
    "#max_features= 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and i found increase ngram can improve accuracy too\n",
    "i change ngram from (1,2) to (1,6) and feature max=50000\n",
    "i get 0.488 from 0.46 at the same 50000 feature.\n",
    "\n",
    "### else method include bag of word(iltk) and dicition tree \n",
    "## i found dicition tree will overfitting and get bad accuracy(0.2) on test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "# part 1\n",
    "\n",
    "---\n",
    "### ** >>> Exercise 1 (Take home): **  \n",
    "Plot word frequency for Top 30 words in both train and test dataset. (Hint: refer to DM lab 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#count vector\n",
    "train_count = CountVectorizer(stop_words = 'english')\n",
    "test_count = CountVectorizer(stop_words = 'english')\n",
    "X_train_counts = train_count.fit_transform(train_df.text)\n",
    "X_test_counts = test_count.fit_transform(test_df.text)\n",
    "print('train shape:', X_train_counts.shape)\n",
    "print('test shape:', X_test_counts.shape)\n",
    "\n",
    "#to pd\n",
    "X_train_count_pd = pd.DataFrame(columns = train_count_vect.get_feature_names(), data = X_train_counts.toarray())\n",
    "X_test_count_pd = pd.DataFrame(columns = test_count_vect.get_feature_names(), data = X_test_counts.toarray())\n",
    "\n",
    "#sort 30\n",
    "test_30 = X_test_count_pd.sum().sort_values(ascending=False)[:30]\n",
    "train_30 = X_train_count_pd.sum().sort_values(ascending=False)[:30]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#show picture\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.bar(train_30.index, train_30, label = 'word frequencies', align = 'edge')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"[Snapshot](img/pic1.png)\"\n",
    "<img src=\"img/pic1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 2 (Take home): **  \n",
    "Generate an embedding using the TF-IDF vectorizer instead of th BOW one with 1000 features and show the feature names for features [100:110]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "tfidf.fit(train_df['text'])\n",
    "#get name\n",
    "feature_names = tfidf.get_feature_names()\n",
    "feature_names[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"[Snapshot](img/pic2.png)\"\n",
    "<img src=\"img/pic2.png\" />\n",
    "\n",
    "---\n",
    "### ** >>> Exercise 3 (Take home): **  \n",
    "# Can you interpret the results above? What do they mean?\n",
    "\n",
    "---\n",
    "A: training accuracy: 0.99,testing accuracy: 0.66. so it is overfitting.\n",
    "\n",
    "And in the confution matrix, anger has the best accuracy.\n",
    "\n",
    "---\n",
    "### ** >>> Exercise 4 (Take home): **  \n",
    "Build a model using a ```Naive Bayes``` model and train it. What are the testing results? \n",
    "\n",
    "*Reference*: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NBmodel = MultinomialNB()\n",
    "NBmodel.fit(X_train, y_train)\n",
    "print('train accuracy:', NBmodel.score(X_train, y_train))\n",
    "print('test accuracy:', NBmodel.score(X_test, y_test))\n",
    "y_test_pred = NBmodel.predict(X_test)\n",
    "\n",
    "# plot your confusion matrix\n",
    "cm2 = confusion_matrix(y_true=y_test, y_pred=y_test_pred) \n",
    "my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
    "plot_confusion_matrix(cm2, classes=my_tags, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"[Snapshot](img/pic3.png)\"\n",
    "<img src=\"img/pic3.png\" style=\"width: 300px;\"/>\n",
    "---\n",
    "### ** >>> Exercise 5 (Take home): **  \n",
    "\n",
    "How do the results from the Naive Bayes model and the Decision Tree model compare? How do you interpret these differences? Use the theoretical background covered in class to try and explain these differences.\n",
    "\n",
    "---\n",
    "A:decition tree is overfitting, Naive has a lower training score,but maybe can increase its acuuracy by bigger data.\n",
    "\n",
    "---\n",
    "---\n",
    "### ** >>> Exercise 6 (Take home): **  \n",
    "\n",
    "Plot the Training and Validation Accuracy and Loss (different plots), just like the images below (Note: the pictures below are an example from a different model). How to interpret the graphs you got? How are they related to the concept of overfitting/underfitting covered in class?\n",
    "<table><tr>\n",
    "    <td><img src=\"pics/pic3.png\" style=\"width: 300px;\"/> </td>\n",
    "    <td><img src=\"pics/pic4.png\" style=\"width: 300px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "# accuracy\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(training_log.epoch, training_log.accuracy, training_log.epoch, training_log.val_accuracy)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.legend([\"training accuracy\", \"val_accuracy\"])\n",
    "plt.title(\"Training accuracy per epoch\")\n",
    "\n",
    "# loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(training_log.epoch, training_log.loss, training_log.epoch, training_log.val_loss)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend([\"training loss\", \"val_loss\"])\n",
    "plt.title(\"Training loss per epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/pic4.png\" />\n",
    "\n",
    "---\n",
    "### ** >>> Exercise 7 (Take home): **  \n",
    "\n",
    "Now, we have the word vectors, but our input data is a sequence of words (or say sentence). \n",
    "How can we utilize these \"word\" vectors to represent the sentence data and train our model?\n",
    "\n",
    "---\n",
    "A: use like k-means or other Neurol network classify model\n",
    "\n",
    "---\n",
    "### ** >>> Exercise 8 (Take home): **  \n",
    "\n",
    "Generate a t-SNE visualization to show the 15 words most related to the words \"angry\", \"happy\", \"sad\", \"fear\" (60 words total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "from sklearn.manifold import TSNE\n",
    "word_list = ['happy', 'angry', 'data', 'mining']\n",
    "\n",
    "\n",
    "topn = 15\n",
    "angry_words = ['angry'] + [word_ for word_, sim_ in w2v_google_model.most_similar('angry', topn=topn)]        \n",
    "happy_words = ['happy'] + [word_ for word_, sim_ in w2v_google_model.most_similar('happy', topn=topn)]\n",
    "sad_words = ['sad'] + [word_ for word_, sim_ in w2v_google_model.most_similar('sad', topn=topn)]        \n",
    "fear_words = ['fear'] + [word_ for word_, sim_ in w2v_google_model.most_similar('fear', topn=topn)]\n",
    "\n",
    "target_words = happy_words + angry_words + sad_words + fear_words\n",
    "\n",
    "cn = topn + 1\n",
    "color = ['b'] * cn + ['g'] * cn + ['r'] * cn + ['y'] * cn\n",
    "\n",
    "## w2v model\n",
    "model = w2v_google_model\n",
    "\n",
    "## prepare training word vectors\n",
    "size = 200\n",
    "target_size = len(target_words)\n",
    "all_word = list(model.vocab.keys())\n",
    "word_train = target_words + all_word[:size]\n",
    "X_train = model[word_train]\n",
    "\n",
    "## t-SNE model\n",
    "tsne = TSNE(n_components=2, metric='cosine', random_state=28)\n",
    "\n",
    "## training\n",
    "X_tsne = tsne.fit_transform(X_train)\n",
    "\n",
    "## show picture\n",
    "plt.figure(figsize=(7.5, 7.5), dpi=115)\n",
    "plt.scatter(X_tsne[:target_size, 0], X_tsne[:target_size, 1], c=color)\n",
    "for label, x, y in zip(target_words, X_tsne[:target_size, 0], X_tsne[:target_size, 1]):\n",
    "    plt.annotate(label, xy=(x,y), xytext=(0,0),  textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/pic5.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
